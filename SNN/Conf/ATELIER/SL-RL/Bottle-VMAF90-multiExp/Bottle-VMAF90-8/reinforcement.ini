[ReinforcementAdamStrength]
type=reinforcementModel
value=0.0008

[gamma]
value=0.8

[entropy_beta]
value=0.01

[qoe_threshold]
type=reinforcementModel
value=80.0

[ReinforceCustomModel]
type=reinforcementModel
value=ActorCriticModel

[reinforcement_embedding]
type=reinforcementModel
value=ActorCriticEmb

[max_steps]
value=10000

[state_dim]
type=reinforcementModel
value=12

[reinforce_actions]
type=reinforcementModel
value=3

[reinforceInputShape]
type=reinforcementModel
value=(${state_dim:value},)

[reinforcementLayers]
type=reinforcementModel
value=['reinforceAction', 'reinforceCritic', 'reinforceInput', 'reinforceCommon']

[common_n_nodes]
type=reinforcementModel
value=128

[common_activation]
type=reinforcementModel
value=relu

[action_activation]
type=reinforcementModel
value=softmax

[memory_utilization]
value=5000

[reward_class_flag]
value=True

[comulativeGammaRew]
value=0.5

[comulativeMtRoundRew]
value=4

[comulativeMtDeltaRew]
value=0.01

[RewardFunction]
value=comulativeAccuracySign

[expansionRoundDecimals]
value=4

[max_param]
value=1200

[ObsPP_class_flag]
value=True

[obsPP_window_avg]
value=5

[ObservationPreProcessing]
value=cmExp_movingAvg

[perfEval_class_flag]
value=True

[PerfEvalRewardThreshold]
value=0.05

[PerfEvalLastSteps]
value=-1

[PerfEvalEpThreshold]
value=30

[avgRew_epPeriod]
value=10

[PerfEval]
value=AvgRewardThreshold

[stop_thresholds]
value=True

[EnvExit_stpThreshold]
value=20

[action_interleave]
value=5
